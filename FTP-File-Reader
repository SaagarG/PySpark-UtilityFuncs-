def read_file_from_ftp(spark, ftp_server, file_path, file_format='csv', sep='\t', username=None, password=None):
    # Define FTP URL
    ftp_url = f"ftp://{username}:{password}@{ftp_server}/{file_path}"

    # Read file based on format
    if file_format.lower() == 'csv':
        df = spark.read.csv(ftp_url, header=True, inferSchema=True)
    elif file_format.lower() == 'tsv' or file_format.lower() == 'tab':
        df = spark.read.csv(ftp_url, sep=sep, header=True, inferSchema=True)
    else:
        raise ValueError("Unsupported file format. Supported formats: 'csv', 'tsv' or 'tab'.")

    return df
------------------------------------------------------------------------------------------------------------------------------
%livy2.pyspark

try :
     spark = SparkSession.builder.appName("ReadFileFromFTP").getOrCreate()

     ds = read_file_from_ftp(spark, "tbl_Lookup_Months.csv")
     ds.show()

except Exception as e :
     print("An Error occured:", str(e))
     
finally :
     spark.stop()

----------------------------------

with tempfile.NamedTemporaryFile(delete=False) as tmp_file:
    tmp_file.write(data)
    tmp_file_path = tmp_file.name

-----------------------------------

file_path = f"/HedgingTbls/TBL_2_Archive_SAPExtract.txt"
ftp = ftplib.FTP(host="emft-xxxxxxx.com", user="yyyy", passwd="zzzz")  # setting up the ftp connection
file = BytesIO()

ftp.retrbinary('RETR ' + file_path, file.write, 1024)
file.seek(0)

with tempfile.NamedTemporaryFile(delete=False) as tmp_file:
     tmp_file.write(file)
     tmp_file_path = tmp_file.name


# Read file based on format
df = spark.read.csv(tmp_file_path, sep="\t", \
                    header=True, \
                    encoding = "UTF-8", \
                    inferSchema = True)
                    #na_values = na_values)
                    
df.printSchema()
-----------------------------------------

 Archive.select(to_date(col('Sale_Dt'), 'd/M/yyyy').alias('Sale_Dt').cast('date'))
